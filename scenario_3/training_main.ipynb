{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from ds_loader import Dataset_Handler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "import torch.nn.functional as F\n",
    "import net\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Initialise some things\n",
    "'''\n",
    "class Config():\n",
    "    batch_size = 32\n",
    "    epochs = 20\n",
    "    learn_rate = 0.0001\n",
    "    CLASSES = 5\n",
    "    generate = False\n",
    "dsh = Dataset_Handler(dataset_folder='sleep_lab_data', target_hertz=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Generate the data and store localy\n",
    "'''\n",
    "if Config.generate: dsh.generate_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WK': 1223, 'N1': 325, 'N2': 1871, 'N3': 1462, 'REM': 1158}\n",
      "{'WK': 1223, 'N1': 1300, 'N2': 1871, 'N3': 1462, 'REM': 1158}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Load Data(numpy array) from disk)\n",
    "if you change modality change network input channels too\n",
    "'''\n",
    "train_dl, test_dl = dsh.get_dataloader(hertz=50,modality=\"baseline.npy\", batch_size=Config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = net.SimpleNet()\n",
    "model.to(device)\n",
    "\n",
    "# define optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=Config.learn_rate)\n",
    "# define loss function\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "Config.batch_size = 258\n",
    "# check if model is on correct device\n",
    "next(model.parameters()).is_cuda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yea we found better weights --> SAVE!!!\n",
      "===> Epoch: 0 loss: 1.2131\n",
      "Yea we found better weights --> SAVE!!!\n",
      "===> Epoch: 1 loss: 0.7430\n",
      "Yea we found better weights --> SAVE!!!\n",
      "===> Epoch: 2 loss: 0.6188\n",
      "Yea we found better weights --> SAVE!!!\n",
      "===> Epoch: 3 loss: 0.5283\n",
      "Yea we found better weights --> SAVE!!!\n",
      "===> Epoch: 4 loss: 0.4560\n",
      "Yea we found better weights --> SAVE!!!\n",
      "===> Epoch: 5 loss: 0.4003\n",
      "Yea we found better weights --> SAVE!!!\n",
      "===> Epoch: 6 loss: 0.3441\n",
      "Yea we found better weights --> SAVE!!!\n",
      "===> Epoch: 7 loss: 0.2969\n",
      "Yea we found better weights --> SAVE!!!\n",
      "===> Epoch: 8 loss: 0.2366\n",
      "Yea we found better weights --> SAVE!!!\n",
      "===> Epoch: 9 loss: 0.1984\n"
     ]
    }
   ],
   "source": [
    "# Traning Process\n",
    "loss_ls_train = []\n",
    "best_epoch_loss = np.infty\n",
    "model.train()\n",
    "\n",
    "for epoch in range(Config.epochs):\n",
    "    epoch_loss_sum = 0\n",
    "    for data, labels in train_dl:\n",
    "\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        data = data.permute(0, 2, 1)\n",
    "        data = data.unsqueeze(2)\n",
    "\n",
    "        prediction = model(data)\n",
    "\n",
    "        loss = loss_function(prediction, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss_sum += loss.data.item()\n",
    "        epoch_loss_average = epoch_loss_sum/len(train_dl)\n",
    "    loss_ls_train.append(epoch_loss_average)\n",
    "\n",
    "\n",
    "    if epoch_loss_average < best_epoch_loss:\n",
    "\n",
    "        best_epoch_loss = epoch_loss_average\n",
    "        state = {'model_state': model.state_dict(),\n",
    "                 'model_name': type(model).__name__,\n",
    "                 'optimizer_state': optimizer.state_dict()}\n",
    "\n",
    "        torch.save(state, \"weights.pt\")\n",
    "        print(\"Yea we found better weights --> SAVE!!!\")\n",
    "\n",
    "    print('===> Epoch: {} loss: {:.4f}'.format(epoch, epoch_loss_average))\n",
    "\n",
    "plt.plot(loss_ls_train)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"weights.pt\")['model_state'])\n",
    "model.eval()\n",
    "\n",
    "correct_pred = 0\n",
    "num_pred = 0\n",
    "map_sum = 0\n",
    "f1_sum = 0\n",
    "count = 0\n",
    "\n",
    "\n",
    "for data, label in test_dl:\n",
    "    data, label = data.to(device), label.to(device)\n",
    "\n",
    "    data = data.permute(0, 2, 1)\n",
    "    data = data.unsqueeze(2)\n",
    "    softmax_v = F.softmax(model(data), dim=1)\n",
    "    pred = torch.argmax(softmax_v, dim=1)\n",
    "\n",
    "    num_pred += len(label)\n",
    "    correct_pred = correct_pred + torch.eq(pred,label).sum().data.item()\n",
    "\n",
    "    #tmp_map, _ = computeMeanAveragePrecision(label.detach().cpu().numpy(), softmax_v.detach().cpu().numpy())\n",
    "    #map_sum += tmp_map\n",
    "    count +=1\n",
    "\n",
    "    f1_sum += f1_score(y_true=label.detach().cpu().numpy(), y_pred=pred.detach().cpu().numpy(), average='micro' )\n",
    "\n",
    "print('Number of correct predictions: ' + str(correct_pred))\n",
    "print('Number of Predictions:' + str(num_pred))\n",
    "print('Accuracy: ' + str(correct_pred/num_pred))\n",
    "print('F1-score: ' + str(f1_sum/count))\n",
    "print('MAP: ' + str(map_sum/count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4292a5c914fcd05fb4d8ac8c1d5d28a6c40b7905c45267b6117bb260a6ea755d"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}